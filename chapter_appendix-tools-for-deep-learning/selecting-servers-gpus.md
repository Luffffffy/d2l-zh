# 选择服务器和 GPU
:label:`sec_buy_gpu`

深度学习培训通常需要大量的计算。目前，GPU 是最具成本效益的深度学习硬件加速器。特别是，与 CPU 相比，GPU 更便宜并且提供更高的性能，通常超过一个数量级。此外，单台服务器可以支持多个 GPU，对于高端服务器，最多可支持 8 个 GPU。更典型的数字是工程工作站最多 4 个 GPU，因为热、冷却和电力需求迅速上升，超出了办公楼所能支持的范围。对于较大的部署而言，云计算（例如亚马逊的 [P3](https://aws.amazon.com/ec2/instance-types/p3/) 和 [G4](https://aws.amazon.com/blogs/aws/in-the-works-ec2-instances-g4-with-nvidia-t4-gpus/) 实例）是一种更实用的解决方案。 

## 选择服务器

通常不需要购买带有许多线程的高端 CPU，因为大部分计算都发生在 GPU 上。也就是说，由于 Python 中的全局解释器锁定 (GIL)，在我们有 4-8 个 GPU 的情况下，CPU 的单线程性能可能很重要。所有情况都相同，这表明内核数量较少但时钟频率更高的 CPU 可能是更经济的选择。例如，在 6 核 4 GHz 和 8 核 3.5 GHz CPU 之间进行选择时，前者更可取，尽管总速度较低。一个重要的考虑因素是 GPU 使用大量功率，从而消散大量热量。这需要非常好的冷却能力和足够大的机箱来使用 GPU。如果可能，请遵循以下指南： 

1. ** 电源 **。GPU 使用了大量的功率。每台设备最多 350W 的预算（由于高效代码可以消耗大量能源，因此检查显卡的 * 峰值需求 * 而不是典型的需求）。如果你的电源不能满足需求，你会发现你的系统变得不稳定。
1. ** 机箱尺寸 **。GPU 很大，辅助电源连接器通常需要额外的空间。此外，大型机箱更容易冷却。
1. ** GPU 冷却 **。如果你有大量 GPU，你可能想投资于水冷。此外，即使风扇较少，也可以追求 * 参考设计 *，因为它们足够薄，可以在设备之间进入空气。如果你购买多个风扇 GPU，它可能太厚而无法在安装多个 GPU 时获得足够的空气，你将遇到热量限制。
1. **PCIe 老虎机 **。将数据移出 GPU（以及在 GPU 之间交换）需要大量带宽。我们建议使用 16 个通道的 PCIe 3.0 插槽。如果您安装多个 GPU，请务必仔细阅读主板说明，以确保同时使用多个 GPU 时仍可使用 16 倍的带宽，并且您将获得 PCIe 3.0，而对于额外插槽而不是 PCIe 2.0。在安装了多个 GPU 的情况下，有些主板降级到 8 倍甚至 4 倍的带宽。部分原因是 CPU 提供的 PCIe 通道数量。

简而言之，以下是构建深度学习服务器的一些建议： 

* ** 初学者 **。购买低功耗的低端 GPU（适合深度学习的廉价游戏 GPU 使用 150-200W）。如果你幸运的话，你当前的计算机将支持它。
* **1 GPU**。拥有 4 个核心的低端 CPU 足够了，大多数主板就足够了。瞄准至少 32 GB 的 DRAM，并投资于固态硬盘以便访问本地数据。600W 的电源应该足够了。购买一个拥有很多粉丝的 GPU。
* **2 个 GPU **。拥有 4-6 个内核的低端 CPU 就足够了。瞄准 64 GB DRAM 并投资于固态硬盘。对于两个高端 GPU，您将需要 1000W 的大小。就主板而言，确保它们有 * 两个 * PCIe 3.0 x16 插槽。如果可以的话，请获得一个 PCIe 3.0 x16 插槽之间有两个空闲空间（60mm 间距）的主板，用于额外的空气。在这种情况下，购买两个带有很多粉丝的 GPU。
* **4 个 GPU **。确保购买单线程速度相对较快的 CPU（即时钟频率高）。您可能需要一个具有更多 PCIe 通道的 CPU，例如 AMD Threadripper。您可能需要相对昂贵的主板才能获得 4 个 PCIe 3.0 x16 插槽，因为它们可能需要 PLX 来复用 PCIe 通道。购买具有狭窄的参考设计的 GPU，让 GPU 之间的空气进入。你需要 1600-2000 瓦的电源，你办公室的插座可能不支持这一点。这台服务器可能会运行 * 响亮而热 *。你不想在办公桌下。建议使用 128 GB 的 DRAM。获取用于本地存储的 SSD（1-2 TB nVMe）和 RAID 配置中的一堆硬盘来存储数据。
* **8 个 GPU **。您需要购买具有多个冗余电源的专用多 GPU 服务器机箱（例如，每个电源为 1600W 2+1）。这将需要双插槽服务器 CPU、256 GB ECC DRAM、快速网卡（推荐使用 10 GBE），并且您需要检查服务器是否支持 GPU 的 * 物理外形 *。消费者 GPU 和服务器 GPU 之间的气流和布线布置显著不同（例如，RTX 2080 与特斯拉 V100）。这意味着您可能无法在服务器中安装消费者 GPU，原因是电源线的间隙不足或缺乏合适的线束（正如其中一位合著者痛苦地发现的那样）。

## 选择 GPU

目前，AMD 和 NVIDIA 是专用 GPU 的两个主要制造商。NVIDIA 是第一个进入深度学习领域的公司，并通过 CUDA 为深度学习框架提供更好的支持。因此，大多数买家选择 NVIDIA GPU。 

NVIDIA 提供两种类型的 GPU，针对个人用户（例如，通过 GTX 和 RTX 系列）和企业用户（通过其特斯拉系列）。这两种类型的 GPU 提供了相当的计算能力。但是，企业用户 GPU 通常使用（被动）强制冷却、更多内存和 ECC（纠错）内存。这些 GPU 更适合数据中心，通常是消费者 GPU 的十倍。 

如果你是一家拥有 100 多台服务器的大公司，你应该考虑 NVIDIA Tesla 系列，或者在云中使用 GPU 服务器。对于拥有 10 台以上服务器的实验室或中小型公司来说，NVIDIA RTX 系列可能最具成本效益。您可以购买具有高效容纳 4-8 个 GPU 的 Supermicro 或华硕机箱的预配置服务器。 

GPU 供应商通常每 1-2 年发布一次新一代，例如 2017 年发布的 GTX 1000（帕斯卡尔）系列和 2019 年发布的 RTX 2000（图灵）系列。每个系列都提供了几种不同的型号，可提供不同的性能GPU 性能主要是以下三个参数的组合： 

1. ** 计算能力 **。一般来说，我们寻找 32 位浮点计算能力。16 位浮点训练 (FP16) 也正在进入主流。如果你只对预测感兴趣，你也可以使用 8 位整数。最新一代图灵 GPU 提供 4 位加速。不幸的是，目前训练低精度网络的算法还不普遍。
1. ** 内存大小 **。随着模型变大或训练期间使用的批量越来越大，您将需要更多的 GPU 内存。检查 HBM2（高带宽内存）与 GDDR6（图形 DDR）内存。HBM2 更快但昂贵得多。
1. ** 内存带宽 **。只有在有足够的内存带宽时，才能充分利用计算能力。如果使用 GDDR6，请寻找宽内存总线。

对于大多数用户来说，看计算能力就足够了。请注意，许多 GPU 提供不同类型的加速。例如，NVIDIA 的 TensorCore 将运营商的子集加速 5 倍。确保你的图书馆支持这一点。GPU 内存应不低于 4 GB（8 GB 好得多）。尽量避免同时使用 GPU 来显示 GUI（改用内置图形）。如果你无法避免它，为了安全起见，请额外添加 2 GB 的 RAM。 

:numref:`fig_flopsvsprice` 比较了各种 GTX 900、GTX 1000 和 RTX 2000 系列机型的 32 位浮点计算能力和价格。价格是维基百科上的建议价格。 

![Floating-point compute power and price comparison. ](../img/flopsvsprice.svg)
:label:`fig_flopsvsprice`

我们可以看到很多东西： 

1. 在每个系列中，价格和性能大致成比例。为了获得更大量的 GPU 内存，泰坦模型获得了显著的溢价。但是，较新的机型提供了更好的成本效益，正如比较 980 Ti 和 1080 Ti 可以看出的那样。对于 RTX 2000 系列来说，价格似乎没有太大改善。但是，这是因为它们提供了远远优越的低精度性能（FP16、INT8 和 INT4）。
2. GTX 1000 系列的性能与成本比率大约是 900 系列的两倍。
3. 对于 RTX 2000 系列，价格是价格的 * AFFIN* 函数。

![Floating-point compute power and energy consumption. ](../img/wattvsprice.svg)
:label:`fig_wattvsprice`

:numref:`fig_wattvsprice` 显示了能耗如何主要与计算量线性扩展。其次，后代效率更高。这似乎与 RTX 2000 系列相对应的图表相矛盾。但是，这是 TensorCore 的结果，它吸收了过多的能量。 

## 摘要

* 构建服务器时，请注意电源、PCIe 总线、CPU 单线程速度和冷却。
* 如果可能的话，你应该购买最新一代 GPU。
* 使用云进行大规模部署。
* 高密度服务器可能不兼容所有 GPU。购买前请查看机械和冷却规格。
* 使用 FP16 或更低的精度来实现高效率。

[Discussions](https://discuss.d2l.ai/t/425)
